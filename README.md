# Simple ETL process with KNIME

1. [Business Understanding](#Business-Understanding)
2. [Data Understanding](#Data-Understanding)
3. [Data Preparation](#Data-Preparation)
4. [Modeling](#.Modeling)
5. [Evaluation](#Evaluation)
6. [Deployment](#Deployment)

## Business Understanding

In this project, we use chess game records from Lichess.org as the dataset. Process that could be applied to this data is concatinating (append) the data because it only consist of 1 table/file.

## Data Understanding

- Number of rows: 20058
- Number of columns: 16

### Columns detail
1. **Id**: Game identifier;
2. **Rated**: Wether the game is rated or not;
3. **Created_at**: Start time;
4. **Last_move_at**: End Time;
5. **Turns**: Number of turns;
6. **Victory_status**: Game status;
7. **Winner**: wether black or white;
8. **Increment_code**: Time increment mode;
9. **White_id**: White player identifier;
10. **White_rating**: White player rating;
11. **Black_id**: Black player identifier;
12. **Black_rating**: Black player rating;
13. **Moves**: All Moves in Standard Chess Notation;
14. **Opening_eco**: Standardised Code for any given opening, [(list here)](https://www.365chess.com/eco.php);
15. **Opening_name**: Opening Name;
16. **Opening_ply**: Number of moves in the opening phase;

## Data Preparation

The dataset will be splitted into 2 part, the 19058 first rows will still be CSV file, and the rest rows will be JSON file.

1. Use text editor to move the 2nd part (100 rows) of dataset to new CSV file.
2. Save the 1st part (19058 rows) of dataset to new CSV file
3. Use online converter ([CSV to JSON](https://www.csvjson.com/csv2json)) to convert 2nd part of dataset from CSV into JSON.
4. Download the converter result as JSON file.

## Modeling

### Data extraction from 2 different sources

1. CSV file:
    1. Add **CSV reader**;
    1. Set the input location to your CSV file location;
    1. Check support short lines and has column header;
    1. Uncheck has row header due duplicate row IDs;
    1. Execute.
2. JSON file:
    1. Add **JSON reader**;
    1. Set the input location to your JSON file location;
    1. Add **JSON to Table**;
    1. Set the **JSON reader** as input data.;
    1. Set 'Arrays' section to 'Expand to columns';
    1. Set 'children Expansion' section to 'only up to level 1';
    1. Add **Transpose** with **JSON to Table**'s output as the input;
    1. Add **Json to Table** with **Transpose**'s output as input;
    1. Execute.

## Evaluation

### Concatenate

1. Add **Concatenate**;
1. Set **CSV Reader**'s output and the last **Json to Table**'s output as the input of **Concatenate**;
1. Execute.

The number of rows generated by the ETL equals the number of rows in the original data which means the ETL process was successful.

## Deployment

### Excel Writer

1. Add **Excel writer** with **Concatenate**'s output as input;
1. Set output file location;
1. Select the desired column to be included;
1. Execute.
